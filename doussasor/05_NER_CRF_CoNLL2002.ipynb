{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"05_NER_CRF_CoNLL2002.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"qGtbcoWtwxq-"},"source":["<span style=\"color:red\">**Team members / emails**</span> --> *To be sent 8th of january, 8pm (Ex. 6)*\n","- (1)\n","- (2)\n","- (3)"]},{"cell_type":"markdown","metadata":{"id":"Ao6cac1HwxrW"},"source":["#### For source code, see\n","1. https://eli5.readthedocs.io/en/latest/tutorials/sklearn_crfsuite.html#\n","2. https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html\n","\n","#### For CRF theory, see\n","1. https://medium.com/ml2vec/overview-of-conditional-random-fields-68a2a20fa541\n","2. https://www.cs.upc.edu/~aquattoni/AllMyPapers/crf_tutorial_talk.pdf\n","3. http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/\n","\n","#### More detailled theoretical ref.\n","1. https://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf\n"]},{"cell_type":"code","metadata":{"id":"W2yDhqjwwxrZ"},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","plt.style.use('ggplot')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEqlFkKrw418","executionInfo":{"status":"ok","timestamp":1610122257595,"user_tz":-60,"elapsed":4897,"user":{"displayName":"Antoine Rodriguez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWYAKZ6xUJQN7qpqVPBvtiEwWSL7w9FYX80Byzxw=s64","userId":"11143032780902899960"}},"outputId":"62aa26ac-2d36-4291-811f-4de6313640e1"},"source":["!pip3 install sklearn_crfsuite"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sklearn_crfsuite\n","  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n","Collecting python-crfsuite>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n","\u001b[K     |████████████████████████████████| 747kB 5.4MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.15.0)\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n","Installing collected packages: python-crfsuite, sklearn-crfsuite\n","Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etdOOpoyxE5C","executionInfo":{"status":"ok","timestamp":1610122299330,"user_tz":-60,"elapsed":4095,"user":{"displayName":"Antoine Rodriguez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWYAKZ6xUJQN7qpqVPBvtiEwWSL7w9FYX80Byzxw=s64","userId":"11143032780902899960"}},"outputId":"a51fe6ef-60a4-4df0-e608-69e2e003878b"},"source":["!pip3 install eli5"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting eli5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n","\r\u001b[K     |███                             | 10kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 5.2MB/s \n","\u001b[?25hRequirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (20.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.19.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.15.0)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (1.0.0)\n","Installing collected packages: eli5\n","Successfully installed eli5-0.10.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"goi85D5hwxra","executionInfo":{"status":"ok","timestamp":1610122558208,"user_tz":-60,"elapsed":2884,"user":{"displayName":"Antoine Rodriguez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWYAKZ6xUJQN7qpqVPBvtiEwWSL7w9FYX80Byzxw=s64","userId":"11143032780902899960"}},"outputId":"9f690f03-2356-451d-ab22-0c86d2aebd38"},"source":["import nltk\n","# Do this once to get CoNLL2002: --> nltk.download()\n","import sklearn_crfsuite\n","import eli5\n","import scipy.stats\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn_crfsuite.metrics import flat_f1_score\n","from sklearn_crfsuite.metrics import flat_classification_report\n","from sklearn.model_selection import cross_val_predict\n","from sklearn.metrics import make_scorer\n","from sklearn.model_selection import RandomizedSearchCV"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"BlnCVSp5wxrb"},"source":["## Training data"]},{"cell_type":"markdown","metadata":{"id":"ufoFZsDi0EjI"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":986},"id":"YschEFj6wxrb","executionInfo":{"status":"error","timestamp":1610122563434,"user_tz":-60,"elapsed":1089,"user":{"displayName":"Antoine Rodriguez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWYAKZ6xUJQN7qpqVPBvtiEwWSL7w9FYX80Byzxw=s64","userId":"11143032780902899960"}},"outputId":"69a41d52-9d19-40a1-f8d6-8aeaee715be0"},"source":["train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n","test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))\n","train_sents[0]"],"execution_count":null,"outputs":[{"output_type":"error","ename":"LookupError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mconll2002\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('conll2002')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-5268aaab9ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconll2002\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miob_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'esp.train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconll2002\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miob_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'esp.testb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mconll2002\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('conll2002')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n"]}]},{"cell_type":"markdown","metadata":{"id":"lih7LCCEwxrc"},"source":["## Feature extraction"]},{"cell_type":"markdown","metadata":{"id":"IxjMmj8gwxrl"},"source":["**Features** word identity, word suffix, word shape and word POS tag\n","<br><br>\n","NB: *The istitle() method returns True if all words in a text start with a upper case letter, AND the rest of the word are lower case letters, otherwise False.*"]},{"cell_type":"code","metadata":{"id":"Wxh-909Uwxrl"},"source":["def word2features(sent, i):\n","    word = sent[i][0]\n","    postag = sent[i][1]\n","\n","    features = {\n","        'bias': 1.0,\n","        'word.lower()': word.lower(),\n","        'word[-3:]': word[-3:],\n","        'word.isupper()': word.isupper(),\n","        'word.istitle()': word.istitle(),\n","        'word.isdigit()': word.isdigit(),\n","        'postag': postag,\n","        'postag[:2]': postag[:2],\n","    }\n","    if i > 0:\n","        word1 = sent[i-1][0]\n","        postag1 = sent[i-1][1]\n","        features.update({\n","            '-1:word.lower()': word1.lower(),\n","            '-1:word.istitle()': word1.istitle(),\n","            '-1:word.isupper()': word1.isupper(),\n","            '-1:postag': postag1,\n","            '-1:postag[:2]': postag1[:2],\n","        })\n","    else:\n","        features['BOS'] = True\n","\n","    if i < len(sent)-1:\n","        word1 = sent[i+1][0]\n","        postag1 = sent[i+1][1]\n","        features.update({\n","            '+1:word.lower()': word1.lower(),\n","            '+1:word.istitle()': word1.istitle(),\n","            '+1:word.isupper()': word1.isupper(),\n","            '+1:postag': postag1,\n","            '+1:postag[:2]': postag1[:2],\n","        })\n","    else:\n","        features['EOS'] = True\n","\n","    return features\n","\n","\n","def sent2features(sent):\n","    return [word2features(sent, i) for i in range(len(sent))]\n","\n","def sent2labels(sent):\n","    return [label for token, postag, label in sent]\n","\n","def sent2tokens(sent):\n","    return [token for token, postag, label in sent]\n","\n","X_train = [sent2features(s) for s in train_sents]\n","y_train = [sent2labels(s) for s in train_sents]\n","\n","X_test = [sent2features(s) for s in test_sents]\n","y_test = [sent2labels(s) for s in test_sents]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6f6PDHcEwxrm"},"source":["# 10th word of sentence 0\n","X_train[0][10]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DlRBz340wxrm"},"source":["## Train a CRF model"]},{"cell_type":"markdown","metadata":{"id":"4CDCOlWdwxrn"},"source":["**L-BFGS** Limited-memory BFGS (Broyden–Fletcher–Goldfarb–Shanno) algorithm <br>--> for the gradient descent\n","<br><br>**c1, c2** Regularization weights (L1+L2 regularizations)"]},{"cell_type":"code","metadata":{"id":"d5PZWTNOwxrn"},"source":["crf = sklearn_crfsuite.CRF(\n","    algorithm='lbfgs',\n","    c1=0.1,\n","    c2=0.1,\n","    max_iterations=100,\n","    all_possible_transitions=True,\n",")\n","crf.fit(X_train, y_train);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9S4VdTq0wxro"},"source":["We want to peak good c1 and c2 parameters. We do a 3-fold cross-validation using a given parameters grid and retain the c1 and c2 that yield the best F1-score.\n","<br><br>\n","**Caution**: this can take **a while**...so I give you below my grid search result!"]},{"cell_type":"code","metadata":{"id":"xVhn5KxJwxro"},"source":["#%%time\n","## define fixed parameters and parameters to search\n","#crf = sklearn_crfsuite.CRF(\n","#    algorithm='lbfgs', \n","#    max_iterations=100, \n","#    all_possible_transitions=True\n","#)\n","#params_space = {\n","#    'c1': scipy.stats.expon(scale=0.5),\n","#    'c2': scipy.stats.expon(scale=0.05),\n","#}\n","#\n","## use the same metric for evaluation\n","#f1_scorer = make_scorer(flat_f1_score, \n","#                        average='weighted', labels=labels)\n","#\n","## search\n","#rs = RandomizedSearchCV(crf, params_space, \n","#                        cv=3, \n","#                        verbose=1, \n","#                        n_jobs=-1, \n","#                        n_iter=50, \n","#                        scoring=f1_scorer)\n","#rs.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dI2v4okMwxrp"},"source":["## crf = rs.best_estimator_\n","#print('best params:', rs.best_params_)\n","#print('best CV score:', rs.best_score_)\n","#print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))\n","\n","## MY RESULTS\n","## ----\n","#best params: {'c1': 0.03802979579044823, 'c2': 0.0624535538687852}\n","#best CV score: 0.7492315130798647\n","#model size: 1.79M\n","## ----"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yZQIBDr5wxrp"},"source":["## Display parameter space"]},{"cell_type":"markdown","metadata":{"id":"b31sE6oiwxrq"},"source":["A chart which shows which c1 and c2 values have RandomizedSearchCV checked. Red color means better results, blue means worse."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"oEWAp3Uswxrq"},"source":["#rs.cv_results_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m0hJjBXtwxrq"},"source":["#_x = [s['c1'] for s in rs.cv_results_['params']]\n","#_y = [s['c2'] for s in rs.cv_results_['params']]\n","#_c = [s for s in rs.cv_results_['mean_test_score']]\n","#\n","#fig = plt.figure()\n","#fig.set_size_inches(12, 12)\n","#ax = plt.gca()\n","#ax.set_yscale('log')\n","#ax.set_xscale('log')\n","#ax.set_xlabel('C1')\n","#ax.set_ylabel('C2')\n","#ax.set_title(\"Randomized Hyperparameter Search CV Results (min={:0.3}, max={:0.3})\".format(\n","#   min(_c), max(_c)\n","#))\n","#\n","#ax.scatter(_x, _y, c=_c, s=60, alpha=0.9, edgecolors=[0,0,0])\n","#\n","#print(\"Dark blue => {:0.4}, dark red => {:0.4}\".format(min(_c), max(_c)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qLSl6_FEwxrr"},"source":["# Results with the best estimator\n","\n","#crf = rs.best_estimator_\n","\n","## USING MY RESULTS\n","## ----\n","#best params: {'c1': 0.03802979579044823, 'c2': 0.0624535538687852}\n","crf = sklearn_crfsuite.CRF(\n","    algorithm='lbfgs',\n","    c1=0.03802979579044823,\n","    c2=0.0624535538687852,\n","    max_iterations=100,\n","    all_possible_transitions=True,\n",")\n","crf.fit(X_train, y_train);\n","## ----\n","\n","y_pred = crf.predict(X_test)\n","print(flat_classification_report(\n","    y_test, y_pred, labels=sorted_labels, digits=3\n","))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"teq-nXSswxrr"},"source":["## Inspect model weights"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Y_9DUh4Iwxrs"},"source":["from collections import Counter\n","\n","def print_transitions(trans_features):\n","    for (label_from, label_to), weight in trans_features:\n","        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n","\n","print(\"Top likely transitions:\")\n","print_transitions(Counter(crf.transition_features_).most_common(20))\n","\n","print(\"\\nTop unlikely transitions:\")\n","print_transitions(Counter(crf.transition_features_).most_common()[-20:])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lVkbnzjl0IRG"},"source":["après avoir faire entrainer le modèle "]},{"cell_type":"code","metadata":{"id":"_bMC6CPo0Hp_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1wmchWPDwxrv"},"source":["eli5.show_weights(crf, top=30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M7buZDfIwxrw"},"source":["Some observations:\n","\n","- **9.338 B-ORG word.lower()**:psoe-progresistas - the model remembered names of some entities - maybe it is overfit, or maybe our features are not adequate, or maybe remembering is indeed helpful;\n","- **4.970 I-LOC -1:word.lower()**:calle: “calle” is a street in Spanish; model learns that if a previous word was “calle” then the token is likely a part of location;\n","- **-7.343 O word.isupper(), -8.461 O word.istitle()**: UPPERCASED or TitleCased words are likely entities of some kind;\n","- **-2.097561 O postag:NP** - proper nouns (NP is a proper noun in the Spanish tagset) are often entities.\n"]},{"cell_type":"code","metadata":{"id":"T7wDJeLCwxrw"},"source":["crf_sparse = sklearn_crfsuite.CRF(\n","    algorithm='lbfgs',\n","    c1=20,\n","    c2=0.0624535538687852,\n","    max_iterations=100,\n","    all_possible_transitions=True,\n",")\n","crf_sparse.fit(X_train, y_train);\n","\n","eli5.show_weights(crf_sparse, top=30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RWGJD0e_wxrx"},"source":["## Customize weights visu"]},{"cell_type":"code","metadata":{"id":"zvA1V57Fwxrx"},"source":["eli5.show_weights(crf, top=10, targets=['O', 'B-ORG', 'I-ORG'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8sKo3d2wxry"},"source":["# Check if a feature function works as intended\n","eli5.show_weights(crf, top=10, feature_re='^word\\.is',\n","                  horizontal_layout=False, show=['targets'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qqKSZ1jYwxrz"},"source":["expl = eli5.explain_weights(crf, top=5, targets=['O', 'B-LOC', 'I-LOC'])\n","print(eli5.format_as_text(expl))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6MS0X3ZFwxrz"},"source":["#### <span style=\"color:red\">Exercise 6</span>"]},{"cell_type":"markdown","metadata":{"id":"3zr9mb4Twxr0"},"source":["#### Comparative study between NLTK NER, Spacy NER and CRF NER on the GMB datasets"]},{"cell_type":"markdown","metadata":{"id":"GajLgZFIwxr0"},"source":["We consider the GMB (Groningen Meaning Bank) corpus.\n","<br> **(1)** Load the sentences of the corpus (see below)\n","<br> **(2)** Provide counts on the chunk tags for the train and test sets\n","<br> **(3)** Apply the NLTK NER, SpaCy NER and CRF NER on a test sentence set of the GMB corpus. \n","<br> **(4)** Evaluate the precision, recall and F-Measure for each entity. Provide separated metrics and average.\n","<br> **(5)** Give also these metrics for all classes.\n","<br> **(6)** Compare the three NER approaches"]},{"cell_type":"markdown","metadata":{"id":"aX625xHGwxr0"},"source":["## Read GMB data"]},{"cell_type":"code","metadata":{"id":"A7QyyacNwxr1"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N0ooPaPYwxr1"},"source":["# Reading the csv file\n","df = pd.read_csv('../../../data/GMB/ner_dataset.csv', \n","                 encoding = \"ISO-8859-1\")\n","df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VVpTIJj6wxr2"},"source":["df.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wl5Ud52xwxr3"},"source":["# Displaying the unique tags\n","df['Tag'].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dh1zqxtAwxr3"},"source":["# Checking the null values if any\n","#print(df.head(10))\n","#print(df.isnull().sum())\n","df = df.fillna(method = 'ffill')\n","df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l-1CTzbVwxr4"},"source":["# A class to get the sentence (= list of tuples with tag and pos)\n","class sentence(object):\n","    def __init__(self, df):\n","        self.n_sent = 1\n","        self.df = df\n","        self.empty = False\n","        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n","                                                       s['POS'].values.tolist(),\n","                                                       s['Tag'].values.tolist())]\n","        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n","        self.sentences = [s for s in self.grouped]\n","\n","    def get_text(self):\n","        try:\n","            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n","            self.n_sent += 1\n","            return s\n","        except:\n","            return None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RqMulzQkwxr4"},"source":["getter = sentence(df)\n","\n","# Displaying one full sentence\n","sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n","sentences[0]\n","\n","# Sentence with its pos and tag\n","sent = getter.get_text()\n","print(sent)\n","\n","# Getting all the sentences in the dataset\n","sentences = getter.sentences"],"execution_count":null,"outputs":[]}]}