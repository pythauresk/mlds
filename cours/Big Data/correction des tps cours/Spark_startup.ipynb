{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Spark_startup.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"e93vkkdVvWtF"},"source":["# Pour accéder à Spark Web UI"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rrt_-208vQxb","outputId":"4a696766-3984-451a-d201-8dc81d543d64"},"source":["!pip install pyngrok"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pyngrok\n","  Downloading https://files.pythonhosted.org/packages/ea/63/e086f165125e9bf2e71c0db2955911baaaa0af8947ab5c7b3771bdf4d4d5/pyngrok-5.0.0.tar.gz\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyngrok) (3.13)\n","Building wheels for collected packages: pyngrok\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyngrok: filename=pyngrok-5.0.0-cp36-none-any.whl size=18780 sha256=f9b00eb30db37b0d468068d75184906d7bee0e7122c83b4d471967287dcdfaf3\n","  Stored in directory: /root/.cache/pip/wheels/95/df/23/af8dde08c3fcdc7b966adcacef48ab29aa3b0b1860df5d2b79\n","Successfully built pyngrok\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-5.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JaTwt3iBvion"},"source":["!mkdir ~/.ngrok2\n","!echo \"web_addr: localhost:5050\" > ~/.ngrok2/ngrok.yml"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VvCsulVovnFB","outputId":"9bdf678a-d9b9-4dea-8730-5627c4b91f7f"},"source":["from pyngrok import ngrok\n","\n","active_tunnels = ngrok.get_tunnels()\n","for tunnel in active_tunnels:\n","  public_url = tunnel.public_url\n","  ngrok.disconnect(public_url)\n","\n","ngrok_tunnel = ngrok.connect(4040, return_ngrok_tunnel=True)\n","ngrok_tunnel"],"execution_count":null,"outputs":[{"output_type":"stream","text":[""],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<NgrokTunnel: \"http://08de931c358d.ngrok.io\" -> \"http://localhost:4040\">"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"GyUgd4rfvx0S"},"source":["Le lien affiché ci-dessus (à gauche) permettra d'utiliser Spark Web UI quand Spark sera lancé."]},{"cell_type":"markdown","metadata":{"id":"NcG9w2Sev6Tr"},"source":["# Spark"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mnB60MNBv8Us","outputId":"b69b73df-ad83-4188-d77f-215d4919a369"},"source":["# install Java8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","# download Spark\n","!wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz\n","# unzip it\n","!tar xf spark-3.0.1-bin-hadoop2.7.tgz\n","# install findspark \n","!pip install -q findspark"],"execution_count":null,"outputs":[{"output_type":"stream","text":["t=2020-12-05T11:55:44+0000 lvl=warn msg=\"failed to open private leg\" id=5e8de7946f81 privaddr=localhost:4040 err=\"dial tcp 127.0.0.1:4040: connect: connection refused\"\n","t=2020-12-05T11:55:45+0000 lvl=warn msg=\"failed to open private leg\" id=9f204cf506b3 privaddr=localhost:4040 err=\"dial tcp 127.0.0.1:4040: connect: connection refused\"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0tgR74g5wCmk"},"source":["# Set up required environment variables\n","\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\"\n","\n","import findspark\n","\n","findspark.init(\"spark-3.0.1-bin-hadoop2.7\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kjM8FyePwDxy"},"source":["# pour utiliser l'API RDD, utiliser l'objet sc\n","\n","from pyspark import SparkContext, SparkConf\n","\n","conf = SparkConf().setAppName(\"mon application\").setMaster(\"local[4]\")\n","sc = SparkContext(conf=conf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xUCNqDqNwKJs"},"source":["# pour utiliser l'API Spark SQL, utiliser l'objet spark\n","\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.config(conf=conf).getOrCreate()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5KSOh-BuwRc0"},"source":[""],"execution_count":null,"outputs":[]}]}